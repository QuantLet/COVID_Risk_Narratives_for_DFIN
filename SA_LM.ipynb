{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "General textual tone analysis procedure - using L&M\n",
    "This program is based on the official codes provided by L&M\n",
    "\n",
    "Author: Yuting\n",
    "3 February 2020\n",
    "\"\"\"\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from Load_MasterDictionary import load_masterdictionary # from Generic_Parser.py\n",
    "import string\n",
    "from datetime import datetime\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using the Mac data path\n",
      "(92542, 2)\n",
      "The first piece of text \n",
      " ['what', 'no', 'load', 'money', 'market', 'mutual', 'fund', 'pays', 'percent', 'since', 'this', 'inquiry', 'was', 'recieved', 'yields', 'on', 'an', 'annualized', 'basis', 'have', 'increased', 'for', 'money', 'market', 'mutual', 'funds', 'up', 'to', 'as', 'high', 'as', 'percent', 'for', 'some', 'according', 'to', 'donoghues', 'money', 'fund', 'report', 'box', 'holliston', 'mass', 'another', 'source', 'of', 'information', 'on', 'yields', 'is', 'fund', 'watch', 'regular', 'feature', 'of', 'money', 'magazine', 'about', 'money', 'market', 'funds', 'are', 'now', 'in', 'operation', 'for', 'more', 'information', 'on', 'features', 'such', 'as', 'free', 'check', 'writing', 'minimum', 'initial', 'deposits', 'etc', 'write', 'no', 'load', 'mutual', 'fund', 'association', 'inc', 'valley', 'forge', 'pa', 'few', 'of', 'the', 'major', 'money', 'market', 'funds', 'are', 'rowe', 'price', 'prime', 'reserve', 'fund', 'inc', 'delaware', 'cash', 'reserves', 'capital', 'preservation', 'fund', 'dreyfus', 'liquid', 'assets', 'fidelity', 'daily', 'income', 'trust', 'scudder', 'managed', 'reserves', 'and', 'oppenheimer', 'monetary', 'bridge', 'the', 'simplest', 'way', 'to', 'get', 'information', 'on', 'these', 'funds', 'is', 'to', 'dial', 'the', 'toll', 'free', 'numbers', 'listed', 'and', 'ask', 'for', 'prospectus', 'and', 'application', 'depending', 'on', 'where', 'you', 'live', 'one', 'or', 'more', 'of', 'these', 'numbers', 'may', 'not', 'be', 'available', 'to', 'in', 'state', 'callers', 'since', 'these', 'are', 'no', 'loads', 'funds', 'you', 'must', 'take', 'the', 'initiative', 'no', 'file', 'the', 'application', 'and', 'send', 'your', 'cash', 'directly', 'to', 'the', 'custodian', 'bank', 'noted', 'on', 'the', 'application', 'the', 'funds', 'noted', 'represent', 'only', 'sample', 'watch', 'for', 'advertisements', 'in', 'this', 'newspaper', 'and', 'in', 'the', 'wall', 'street', 'journal', 'for', 'others']\n",
      "CPU times: user 39.1 s, sys: 1min 12s, total: 1min 51s\n",
      "Wall time: 3min 44s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "test_type = 'history'\n",
    "\n",
    "# load processed file\n",
    "path_temp = \"Temp/\"\n",
    "# impoort your data\n",
    "df = pd.read_pickle(path_temp+test_type+'_Processed.pkl')\n",
    "df = df[['date','CONTENT']]\n",
    "\n",
    "if test_type == 'tweet':\n",
    "    start_date = datetime.strptime(\"01/01/2020\", '%d/%m/%Y')\n",
    "#     end_date = datetime.strptime(\"26/05/2020\", '%d/%m/%Y')\n",
    "    df = df.loc[df['date'] >= start_date]\n",
    "    df = df.reset_index()\n",
    "else:\n",
    "#     df.columns = ['time','source','text','country']\n",
    "    df['date'] = pd.to_datetime(df['date'], format='%Y-%m-%d')\n",
    "\n",
    "# preview data\n",
    "print(df.shape)\n",
    "\n",
    "print(\"The first piece of text \\n\",df[\"CONTENT\"][0])\n",
    "\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " ...Loading Master Dictionary 85000\n",
      "Master Dictionary loaded from file: \n",
      "  LoughranMcDonald_MasterDictionary_2018.csv\n",
      "  86,486 words loaded in master_dictionary.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# define the tone analyzers, easy\n",
    "\n",
    "# for L&M\n",
    "MASTER_DICTIONARY_FILE = 'LoughranMcDonald_MasterDictionary_2018.csv'\n",
    "lm_dictionary = load_masterdictionary(MASTER_DICTIONARY_FILE, True)\n",
    "\n",
    "def lm_get_data(doc): # from \"Generic_Parser.py\"\n",
    "\n",
    "    vdictionary = {}\n",
    "    _odata = [0] * 9\n",
    "    total_syllables = 0\n",
    "    word_length = 0\n",
    "    \n",
    "    # if import processed data, comment this line\n",
    "#     tokens = re.findall('\\w+', doc)  # Note that \\w+ splits hyphenated words\n",
    "    tokens = doc\n",
    "    for token in tokens:\n",
    "        token = token.upper()\n",
    "        if not token.isdigit() and len(token) > 1 and token in lm_dictionary:\n",
    "            _odata[0] += 1  # word count\n",
    "            word_length += len(token)\n",
    "            if token not in vdictionary:\n",
    "                vdictionary[token] = 1\n",
    "            if lm_dictionary[token].positive: _odata[1] += 1\n",
    "            if lm_dictionary[token].negative: _odata[2] += 1\n",
    "            if lm_dictionary[token].uncertainty: _odata[3] += 1\n",
    "            if lm_dictionary[token].litigious: _odata[4] += 1\n",
    "            if lm_dictionary[token].weak_modal: _odata[5] += 1\n",
    "            if lm_dictionary[token].moderate_modal: _odata[6] += 1\n",
    "            if lm_dictionary[token].strong_modal: _odata[7] += 1\n",
    "            if lm_dictionary[token].constraining: _odata[8] += 1\n",
    "            total_syllables += lm_dictionary[token].syllables\n",
    "\n",
    "    # Convert counts to % I don't need to\n",
    "#     for i in range(3, 10 + 1):\n",
    "#         _odata[i] = (_odata[i] / _odata[2])\n",
    "    # Vocabulary\n",
    "        \n",
    "    return _odata\n",
    "\n",
    "def lm_sentiment_analyzer(text):\n",
    "    try:\n",
    "#         text = text.upper()\n",
    "        score = lm_get_data(text)\n",
    "    except:\n",
    "        score = [np.nan]*9\n",
    "    return score\n",
    "\n",
    "# for vader\n",
    "def vader_sentiment_analyzer(text):\n",
    "    score = SentimentIntensityAnalyzer().polarity_scores(text)\n",
    "    return score['compound']\n",
    "\n",
    "# for textblob\n",
    "def textblob_sentiment_analyzer(text):\n",
    "    score = TextBlob(text).sentiment.polarity\n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   total  positive  negative  uncertainty  litigious  weak_modal  \\\n",
      "0    202         0         2            2          0           2   \n",
      "1    807         5         3            3          0           3   \n",
      "2    155         1         5            1          0           1   \n",
      "3    626         6        22            7          0           5   \n",
      "4    517         9        14            4          1           2   \n",
      "\n",
      "   moderate_modal  strong_modal  constraining       date  \n",
      "0               0             1             1 1980-01-02  \n",
      "1               2             2             1 1980-01-02  \n",
      "2               0             1             0 1980-01-03  \n",
      "3               2             3             0 1980-01-04  \n",
      "4               6             4             1 1980-01-07  \n",
      "CPU times: user 2min 17s, sys: 30.4 s, total: 2min 48s\n",
      "Wall time: 3min 8s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "data = []\n",
    "for i in df['CONTENT']: ### text or text_first\n",
    "    odata = lm_sentiment_analyzer(i)\n",
    "    data.append(odata)\n",
    "df_tones = pd.DataFrame(data,columns = ['total','positive','negative','uncertainty','litigious','weak_modal','moderate_modal','strong_modal','constraining'])\n",
    "df_tones['date'] = df[\"date\"]\n",
    "print(df_tones.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tones.to_csv(path_temp+test_type+'_LM_tones.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
